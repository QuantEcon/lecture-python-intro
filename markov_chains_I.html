

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>27. Markov Chains: Basic Concepts &#8212; A First Course in Quantitative Economics with Python</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/quantecon-book-theme.css?digest=b09b2da44b9015b4fa76ea072fa2d8f7faee5492" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>


    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/scripts/quantecon-book-theme.js?digest=eed9c059a3ee152aae2353ec732f0a6d12e6aa07"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-QDS1YRJNGM"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-QDS1YRJNGM');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "arg\\,max", "argmin": "arg\\,min"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'markov_chains_I';</script>
    <link rel="canonical" href="https://intro.quantecon.org/markov_chains_I.html" />
    <link rel="shortcut icon" href="_static/lectures-favicon.ico"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="28. Markov Chains: Irreducibility and Ergodicity" href="markov_chains_II.html" />
    <link rel="prev" title="26. AR1 Processes" href="ar1_processes.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Python, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents introductory lectures on computational economics, designed and written by Thomas J. Sargent and John Stachurski. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Markov Chains: Basic Concepts"/>
<meta name="twitter:description" content="This website presents introductory lectures on computational economics, designed and written by Thomas J. Sargent and John Stachurski.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Markov Chains: Basic Concepts" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://intro.quantecon.org/markov_chains_I.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents introductory lectures on computational economics, designed and written by Thomas J. Sargent and John Stachurski." />
<meta property="og:site_name" content="A First Course in Quantitative Economics with Python" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=markov_chains_I>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">27.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions-and-examples">27.2. Definitions and examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-matrices">27.2.1. Stochastic matrices</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-chains">27.2.2. Markov chains</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1">27.2.2.1. Example 1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2">27.2.2.2. Example 2</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-3">27.2.2.3. Example 3</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-markov-chains">27.2.3. Defining Markov chains</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation">27.3. Simulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#writing-our-own-simulation-code">27.3.1. Writing our own simulation code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-quantecons-routines">27.3.2. Using QuantEcon’s routines</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-state-values-and-initial-conditions">27.3.2.1. Adding state values and initial conditions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distributions-over-time">27.4. Distributions over time</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-step-transition-probabilities">27.4.1. Multiple step transition probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-probability-of-recession">27.4.2. Example: probability of recession</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-2-cross-sectional-distributions">27.4.3. Example 2: Cross-sectional distributions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationary-distributions">27.5. Stationary distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">27.5.1. Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-stationary-distributions">27.5.2. Calculating stationary distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#asymptotic-stationarity">27.5.3. Asymptotic stationarity</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-hamiltons-chain">27.5.3.1. Example: Hamilton’s chain</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#an-alternative-illustration">27.5.3.2. An alternative illustration</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-failure-of-convergence">27.5.3.3. Example: Failure of convergence</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-expectations">27.6. Computing expectations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectations-of-geometric-sums">27.6.1. Expectations of geometric sums</a></li>
</ul>
</li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="_static/qe-logo.png" class="logo logo-img" alt="logo"></a>
                                    
                                    <a href=https://quantecon.org><img src="_static/quantecon-logo-transparent.png" class="dark-logo-img" alt="logo"></a>
                                    
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="intro.html">A First Course in Quantitative Economics with Python</a></p>

                        <p class="qe-page__header-subheading">Markov Chains: Basic Concepts</p>

                    </div>
                    <!-- length 2, since its a string and empty dict has length 2 - {} -->
                        <p class="qe-page__header-authors" font-size="18">
                            
                                
                                    <a href="http://www.tomsargent.com/" target="_blank"><span>Thomas J. Sargent</span></a>
                                
                            
                                
                                    and <a href="https://johnstachurski.net/" target="_blank"><span>John Stachurski</span></a>
                                
                            
                        </p>


                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <section class="tex2jax_ignore mathjax_ignore" id="markov-chains-basic-concepts">
<h1><span class="section-number">27. </span>Markov Chains: Basic Concepts<a class="headerlink" href="#markov-chains-basic-concepts" title="Permalink to this heading">#</a></h1>
<p id="index-0">In addition to what’s in Anaconda, this lecture will need the following libraries:</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>quantecon
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: quantecon in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (0.7.1)
Requirement already satisfied: numba&gt;=0.49.0 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from quantecon) (0.57.1)
Requirement already satisfied: numpy&gt;=1.17.0 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from quantecon) (1.24.3)
Requirement already satisfied: requests in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from quantecon) (2.31.0)
Requirement already satisfied: scipy&gt;=1.5.0 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from quantecon) (1.11.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: sympy in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from quantecon) (1.11.1)
Requirement already satisfied: llvmlite&lt;0.41,&gt;=0.40.0dev0 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from numba&gt;=0.49.0-&gt;quantecon) (0.40.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from requests-&gt;quantecon) (2.0.4)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from requests-&gt;quantecon) (3.4)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from requests-&gt;quantecon) (1.26.16)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from requests-&gt;quantecon) (2023.7.22)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/share/miniconda3/envs/quantecon/lib/python3.11/site-packages (from sympy-&gt;quantecon) (1.3.0)
</pre></div>
</div>
</div>
</details>
</div>
<section id="overview">
<h2><span class="section-number">27.1. </span>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>Markov chains are a standard way to model time series with some dependence
between observations.</p>
<p>For example,</p>
<ul class="simple">
<li><p>inflation next year depends on inflation this year</p></li>
<li><p>unemployment next month depends on unemployment this month</p></li>
</ul>
<p>Markov chains are one of the workhorse models of economics and finance.</p>
<p>The theory of Markov chains is beautiful and provides many insights into
probability and dynamics.</p>
<p>In this introductory lecture, we will</p>
<ul class="simple">
<li><p>review some of the key ideas from the theory of Markov chains and</p></li>
<li><p>show how Markov chains appear in some economic applications.</p></li>
</ul>
<p>Let’s start with some standard imports:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">quantecon</span> <span class="k">as</span> <span class="nn">qe</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="definitions-and-examples">
<h2><span class="section-number">27.2. </span>Definitions and examples<a class="headerlink" href="#definitions-and-examples" title="Permalink to this heading">#</a></h2>
<p>In this section we provide the basic definitions and some elementary examples.</p>
<section id="stochastic-matrices">
<span id="finite-dp-stoch-mat"></span><h3><span class="section-number">27.2.1. </span>Stochastic matrices<a class="headerlink" href="#stochastic-matrices" title="Permalink to this heading">#</a></h3>
<p>Recall that a <strong>probability mass function</strong> over <span class="math notranslate nohighlight">\(n\)</span> possible outcomes is a
nonnegative <span class="math notranslate nohighlight">\(n\)</span>-vector <span class="math notranslate nohighlight">\(p\)</span> that sums to one.</p>
<p>For example, <span class="math notranslate nohighlight">\(p = (0.2, 0.2, 0.6)\)</span> is a probability mass function over <span class="math notranslate nohighlight">\(3\)</span> outcomes.</p>
<p>A <strong>stochastic matrix</strong> (or <strong>Markov matrix</strong>)  is an <span class="math notranslate nohighlight">\(n \times n\)</span> square matrix <span class="math notranslate nohighlight">\(P\)</span>
such that each row of <span class="math notranslate nohighlight">\(P\)</span> is a probability mass function over <span class="math notranslate nohighlight">\(n\)</span> outcomes.</p>
<p>In other words,</p>
<ol class="arabic simple">
<li><p>each element of <span class="math notranslate nohighlight">\(P\)</span> is nonnegative, and</p></li>
<li><p>each row of <span class="math notranslate nohighlight">\(P\)</span> sums to one</p></li>
</ol>
<p>If <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix, then so is the <span class="math notranslate nohighlight">\(k\)</span>-th power <span class="math notranslate nohighlight">\(P^k\)</span> for all <span class="math notranslate nohighlight">\(k \in \mathbb N\)</span>.</p>
<p>Checking this in <a class="reference internal" href="#mc1_ex_3"><span class="std std-ref">the first exercises</span></a> below.</p>
</section>
<section id="markov-chains">
<h3><span class="section-number">27.2.2. </span>Markov chains<a class="headerlink" href="#markov-chains" title="Permalink to this heading">#</a></h3>
<p>Now we can introduce Markov chains.</p>
<p>First we will give some examples and then we will define them more carefully.</p>
<p>At that time, the connection between stochastic matrices and Markov chains
will become clear.</p>
<section id="example-1">
<span id="mc-eg2"></span><h4><span class="section-number">27.2.2.1. </span>Example 1<a class="headerlink" href="#example-1" title="Permalink to this heading">#</a></h4>
<p>From  US unemployment data, Hamilton <span id="id1">[<a class="reference internal" href="zreferences.html#id182" title="James D Hamilton. What's real about the business cycle? Federal Reserve Bank of St. Louis Review, pages 435–452, 2005.">Ham05</a>]</span> estimated the following dynamics.</p>
<img alt="_images/Hamilton.png" class="align-center" id="mc-hamilton" src="_images/Hamilton.png" />
<p>Here there are three <strong>states</strong></p>
<ul class="simple">
<li><p>“ng” represents normal growth</p></li>
<li><p>“mr” represents mild recession</p></li>
<li><p>“sr” represents severe recession</p></li>
</ul>
<p>The arrows represent <strong>transition probabilities</strong> over one month.</p>
<p>For example, the arrow from mild recession to normal growth has 0.145 next to it.</p>
<p>This tells us that, according to past data, there is a 14.5% probability of transitioning from mild recession to normal growth in one month.</p>
<p>The arrow from normal growth back to normal growth tells us that there is a
97% probability of transitioning from normal growth to normal growth (staying
in the same state).</p>
<p>Note that these are <em>conditional</em> probabilities — the probability of
transitioning from one state to another (or staying at the same one) conditional on the
current state.</p>
<p>To make the problem easier to work with numerically, let’s convert states to
numbers.</p>
<p>In particular, we agree that</p>
<ul class="simple">
<li><p>state 0 represents normal growth</p></li>
<li><p>state 1 represents mild recession</p></li>
<li><p>state 2 represents severe recession</p></li>
</ul>
<p>Let <span class="math notranslate nohighlight">\(X_t\)</span> record the value of the state at time <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>Now we can write the statement “there is a 14.5% probability of transitioning from mild recession to normal growth in one month” as</p>
<div class="math notranslate nohighlight">
\[
    \mathbb P\{X_{t+1} = 0 \,|\, X_t = 1\} = 0.145
\]</div>
<p>We can collect all of these conditional probabilities into a matrix, as follows</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P =
\begin{bmatrix}
0.971 &amp; 0.029 &amp; 0 \\
0.145 &amp; 0.778 &amp; 0.077 \\
0 &amp; 0.508 &amp; 0.492
\end{bmatrix}
\end{split}\]</div>
<p>Notice that <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix.</p>
<p>Now we have the following relationship</p>
<div class="math notranslate nohighlight">
\[
    P(i,j)
    = \mathbb P\{X_{t+1} = j \,|\, X_t = i\}
\]</div>
<p>This holds for any <span class="math notranslate nohighlight">\(i,j\)</span> between 0 and 2.</p>
<p>In particular, <span class="math notranslate nohighlight">\(P(i,j)\)</span> is the
probability of transitioning from state <span class="math notranslate nohighlight">\(i\)</span> to state <span class="math notranslate nohighlight">\(j\)</span> in one month.</p>
</section>
<section id="example-2">
<span id="mc-eg1"></span><h4><span class="section-number">27.2.2.2. </span>Example 2<a class="headerlink" href="#example-2" title="Permalink to this heading">#</a></h4>
<p>Consider a worker who, at any given time <span class="math notranslate nohighlight">\(t\)</span>, is either unemployed (state 0)
or employed (state 1).</p>
<p>Suppose that, over a one-month period,</p>
<ol class="arabic simple">
<li><p>the unemployed worker finds a job with probability <span class="math notranslate nohighlight">\(\alpha \in (0, 1)\)</span>.</p></li>
<li><p>the employed worker loses her job and becomes unemployed with probability <span class="math notranslate nohighlight">\(\beta \in (0, 1)\)</span>.</p></li>
</ol>
<p>Given the above information, we can write out the transition probabilities in matrix form as</p>
<div class="math notranslate nohighlight" id="equation-p-unempemp">
<span class="eqno">(27.1)<a class="headerlink" href="#equation-p-unempemp" title="Permalink to this equation">#</a></span>\[\begin{split}P =
\begin{bmatrix}
    1 - \alpha &amp; \alpha \\
    \beta &amp; 1 - \beta
\end{bmatrix}\end{split}\]</div>
<p>For example,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    P(0,1)
        &amp; =
        \text{ probability of transitioning from state $0$ to state $1$ in one month}
        \\
        &amp; =
        \text{ probability finding a job next month}
        \\
        &amp; = \alpha
\end{aligned}
\end{split}\]</div>
<p>Suppose we can estimate the values <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<p>Then we can address a range of questions, such as</p>
<ul class="simple">
<li><p>What is the average duration of unemployment?</p></li>
<li><p>Over the long-run, what fraction of the time does a worker find herself unemployed?</p></li>
<li><p>Conditional on employment, what is the probability of becoming unemployed at least once over the next 12 months?</p></li>
</ul>
<p>We’ll cover some of these applications below.</p>
</section>
<section id="example-3">
<span id="mc-eg3"></span><h4><span class="section-number">27.2.2.3. </span>Example 3<a class="headerlink" href="#example-3" title="Permalink to this heading">#</a></h4>
<p>Imam and Temple <span id="id2">[<a class="reference internal" href="zreferences.html#id284" title="Patrick Imam and Jonathan RW Temple. Political institutions and output collapses. IMF Working Paper, 2023.">IT23</a>]</span> categorize political institutions into
three types: democracy <span class="math notranslate nohighlight">\(\text{(D)}\)</span>, autocracy <span class="math notranslate nohighlight">\(\text{(A)}\)</span>, and an intermediate
state called anocracy <span class="math notranslate nohighlight">\(\text{(N)}\)</span>.</p>
<p>Each institution can have two potential development regimes: collapse <span class="math notranslate nohighlight">\(\text{(C)}\)</span> and growth <span class="math notranslate nohighlight">\(\text{(G)}\)</span>. This results in six possible states: <span class="math notranslate nohighlight">\(\text{DG, DC, NG, NC, AG}\)</span> and <span class="math notranslate nohighlight">\(\text{AC}\)</span>.</p>
<p>Imam and Temple <span id="id3">[<a class="reference internal" href="zreferences.html#id284" title="Patrick Imam and Jonathan RW Temple. Political institutions and output collapses. IMF Working Paper, 2023.">IT23</a>]</span> estimate the following transition
probabilities:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P :=
\begin{bmatrix}
0.86 &amp; 0.11 &amp; 0.03 &amp; 0.00 &amp; 0.00 &amp; 0.00 \\
0.52 &amp; 0.33 &amp; 0.13 &amp; 0.02 &amp; 0.00 &amp; 0.00 \\
0.12 &amp; 0.03 &amp; 0.70 &amp; 0.11 &amp; 0.03 &amp; 0.01 \\
0.13 &amp; 0.02 &amp; 0.35 &amp; 0.36 &amp; 0.10 &amp; 0.04 \\
0.00 &amp; 0.00 &amp; 0.09 &amp; 0.11 &amp; 0.55 &amp; 0.25 \\
0.00 &amp; 0.00 &amp; 0.09 &amp; 0.15 &amp; 0.26 &amp; 0.50
\end{bmatrix}
\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DG&#39;</span><span class="p">,</span> <span class="s1">&#39;DC&#39;</span><span class="p">,</span> <span class="s1">&#39;NG&#39;</span><span class="p">,</span> <span class="s1">&#39;NC&#39;</span><span class="p">,</span> <span class="s1">&#39;AG&#39;</span><span class="p">,</span> <span class="s1">&#39;AC&#39;</span><span class="p">]</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<p>Here is a visualization, with darker colors indicating higher probability.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">MultiDiGraph</span><span class="p">()</span>
<span class="n">edge_ls</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">label_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">node_start</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">end_idx</span><span class="p">,</span> <span class="n">node_end</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">start_idx</span><span class="p">][</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">node_start</span><span class="p">,</span><span class="n">node_end</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="nb">len</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_nodes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>

<span class="n">arc_rad</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">curved_edges</span> <span class="o">=</span> <span class="p">[</span><span class="n">edge</span> <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">edges</span><span class="p">()]</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">connectionstyle</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;arc3, rad = </span><span class="si">{</span><span class="n">arc_rad</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">edge_cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">edge_color</span><span class="o">=</span><span class="p">[</span><span class="n">G</span><span class="p">[</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">edges</span><span class="p">])</span>

<span class="n">pc</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">collections</span><span class="o">.</span><span class="n">PatchCollection</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/fad333de1eb6b808a649c63fd156a82cb72c32ef2914aab881e57f86ec91abd2.png"><img alt="_images/fad333de1eb6b808a649c63fd156a82cb72c32ef2914aab881e57f86ec91abd2.png" src="_images/fad333de1eb6b808a649c63fd156a82cb72c32ef2914aab881e57f86ec91abd2.png" style="width: 80%;" /></a>
</div>
</div>
<p>Looking at the data, we see that democracies tend to have longer-lasting growth
regimes compared to autocracies (as indicated by the lower probability of
transitioning from growth to growth in autocracies).</p>
<p>We can also find a higher probability from collapse to growth in democratic regimes.</p>
</section>
</section>
<section id="defining-markov-chains">
<h3><span class="section-number">27.2.3. </span>Defining Markov chains<a class="headerlink" href="#defining-markov-chains" title="Permalink to this heading">#</a></h3>
<p>So far we’ve given examples of Markov chains but now let’s define them more
carefully.</p>
<p>To begin, let <span class="math notranslate nohighlight">\(S\)</span> be a finite set <span class="math notranslate nohighlight">\(\{x_1, \ldots, x_n\}\)</span> with <span class="math notranslate nohighlight">\(n\)</span> elements.</p>
<p>The set <span class="math notranslate nohighlight">\(S\)</span> is called the <strong>state space</strong> and <span class="math notranslate nohighlight">\(x_1, \ldots, x_n\)</span> are the <strong>state values</strong>.</p>
<p>A <strong>distribution</strong> <span class="math notranslate nohighlight">\(\psi\)</span> on <span class="math notranslate nohighlight">\(S\)</span> is a probability mass function of length <span class="math notranslate nohighlight">\(n\)</span>, where <span class="math notranslate nohighlight">\(\psi(i)\)</span> is the amount of probability allocated to state <span class="math notranslate nohighlight">\(x_i\)</span>.</p>
<p>A <strong>Markov chain</strong> <span class="math notranslate nohighlight">\(\{X_t\}\)</span> on <span class="math notranslate nohighlight">\(S\)</span> is a sequence of random variables taking values in <span class="math notranslate nohighlight">\(S\)</span>
that have the <strong>Markov property</strong>.</p>
<p>This means that, for any date <span class="math notranslate nohighlight">\(t\)</span> and any state <span class="math notranslate nohighlight">\(y \in S\)</span>,</p>
<div class="math notranslate nohighlight" id="equation-fin-markov-mp">
<span class="eqno">(27.2)<a class="headerlink" href="#equation-fin-markov-mp" title="Permalink to this equation">#</a></span>\[\mathbb P \{ X_{t+1} = y  \,|\, X_t \}
= \mathbb P \{ X_{t+1}  = y \,|\, X_t, X_{t-1}, \ldots \}\]</div>
<p>In other words, knowing the current state is enough to know probabilities for the future states.</p>
<p>In particular, the dynamics of a Markov chain are fully determined by the set of values</p>
<div class="math notranslate nohighlight" id="equation-mpp">
<span class="eqno">(27.3)<a class="headerlink" href="#equation-mpp" title="Permalink to this equation">#</a></span>\[P(x, y) := \mathbb P \{ X_{t+1} = y \,|\, X_t = x \}
\qquad (x, y \in S)\]</div>
<p>By construction,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(x, y)\)</span> is the probability of going from <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\(y\)</span> in one unit of time (one step)</p></li>
<li><p><span class="math notranslate nohighlight">\(P(x, \cdot)\)</span> is the conditional distribution of <span class="math notranslate nohighlight">\(X_{t+1}\)</span> given <span class="math notranslate nohighlight">\(X_t = x\)</span></p></li>
</ul>
<p>We can view <span class="math notranslate nohighlight">\(P\)</span> as a stochastic matrix where</p>
<div class="math notranslate nohighlight">
\[
    P_{ij} = P(x_i, x_j)
    \qquad 1 \leq i, j \leq n
\]</div>
<p>Going the other way, if we take a stochastic matrix <span class="math notranslate nohighlight">\(P\)</span>, we can generate a Markov
chain <span class="math notranslate nohighlight">\(\{X_t\}\)</span> as follows:</p>
<ul class="simple">
<li><p>draw <span class="math notranslate nohighlight">\(X_0\)</span> from a distribution <span class="math notranslate nohighlight">\(\psi_0\)</span> on <span class="math notranslate nohighlight">\(S\)</span></p></li>
<li><p>for each <span class="math notranslate nohighlight">\(t = 0, 1, \ldots\)</span>, draw <span class="math notranslate nohighlight">\(X_{t+1}\)</span> from <span class="math notranslate nohighlight">\(P(X_t,\cdot)\)</span></p></li>
</ul>
<p>By construction, the resulting process satisfies <a class="reference internal" href="#equation-mpp">(27.3)</a>.</p>
</section>
</section>
<section id="simulation">
<h2><span class="section-number">27.3. </span>Simulation<a class="headerlink" href="#simulation" title="Permalink to this heading">#</a></h2>
<p id="index-1">One natural way to answer questions about Markov chains is to simulate them.</p>
<p>Let’s start by doing this ourselves and then look at libraries that can help
us.</p>
<p>In these exercises, we’ll take the state space to be <span class="math notranslate nohighlight">\(S = 0,\ldots, n-1\)</span>.</p>
<p>(We start at <span class="math notranslate nohighlight">\(0\)</span> because Python arrays are indexed from <span class="math notranslate nohighlight">\(0\)</span>.)</p>
<section id="writing-our-own-simulation-code">
<h3><span class="section-number">27.3.1. </span>Writing our own simulation code<a class="headerlink" href="#writing-our-own-simulation-code" title="Permalink to this heading">#</a></h3>
<p>To simulate a Markov chain, we need</p>
<ol class="arabic simple">
<li><p>a stochastic matrix <span class="math notranslate nohighlight">\(P\)</span> and</p></li>
<li><p>a probability mass function <span class="math notranslate nohighlight">\(\psi_0\)</span> of length <span class="math notranslate nohighlight">\(n\)</span> from which to draw an initial realization of <span class="math notranslate nohighlight">\(X_0\)</span>.</p></li>
</ol>
<p>The Markov chain is then constructed as follows:</p>
<ol class="arabic simple">
<li><p>At time <span class="math notranslate nohighlight">\(t=0\)</span>, draw a realization of <span class="math notranslate nohighlight">\(X_0\)</span> from the distribution <span class="math notranslate nohighlight">\(\psi_0\)</span>.</p></li>
<li><p>At each subsequent time <span class="math notranslate nohighlight">\(t\)</span>, draw a realization of the new state <span class="math notranslate nohighlight">\(X_{t+1}\)</span> from <span class="math notranslate nohighlight">\(P(X_t, \cdot)\)</span>.</p></li>
</ol>
<p>(That is, draw from row <span class="math notranslate nohighlight">\(X_t\)</span> of <span class="math notranslate nohighlight">\(P\)</span>.)</p>
<p>To implement this simulation procedure, we need a method for generating draws
from a discrete distribution.</p>
<p>For this task, we’ll use <code class="docutils literal notranslate"><span class="pre">random.draw</span></code> from <a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a>.</p>
<p>To use <code class="docutils literal notranslate"><span class="pre">random.draw</span></code>, we first need to convert the probability mass function
to a cumulative distribution</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ψ_0</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)</span>           <span class="c1"># probabilities over {0, 1}</span>
<span class="n">cdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">)</span>       <span class="c1"># convert into cumulative distribution</span>
<span class="n">qe</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">cdf</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>   <span class="c1"># generate 5 independent draws from ψ</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 1, 1, 1, 1])
</pre></div>
</div>
</div>
</div>
<p>We’ll write our code as a function that accepts the following three arguments</p>
<ul class="simple">
<li><p>A stochastic matrix <code class="docutils literal notranslate"><span class="pre">P</span></code>.</p></li>
<li><p>An initial distribution <code class="docutils literal notranslate"><span class="pre">ψ_0</span></code>.</p></li>
<li><p>A positive integer <code class="docutils literal notranslate"><span class="pre">ts_length</span></code> representing the length of the time series the function should return.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mc_sample_path</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ψ_0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ts_length</span><span class="o">=</span><span class="mi">1_000</span><span class="p">):</span>

    <span class="c1"># set up</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">ts_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Convert each row of P into a cdf</span>
    <span class="n">P_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Convert rows into cdfs</span>

    <span class="c1"># draw initial state, defaulting to 0</span>
    <span class="k">if</span> <span class="n">ψ_0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">X_0</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_0</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># simulate</span>
    <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_0</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ts_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">P_dist</span><span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="p">:])</span>

    <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see how it works using the small matrix</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s a short time series.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mc_sample_path</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ψ_0</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="n">ts_length</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])
</pre></div>
</div>
</div>
</div>
<p>It can be shown that for a long series drawn from <code class="docutils literal notranslate"><span class="pre">P</span></code>, the fraction of the
sample that takes value 0 will be about 0.25.</p>
<p>(We will explain why <a class="reference internal" href="markov_chains_II.html#ergodicity"><span class="std std-ref">later</span></a>.)</p>
<p>Moreover, this is true regardless of the initial distribution from which
<span class="math notranslate nohighlight">\(X_0\)</span> is drawn.</p>
<p>The following code illustrates this</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">mc_sample_path</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ψ_0</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span> <span class="n">ts_length</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.250118
</pre></div>
</div>
</div>
</div>
<p>You can try changing the initial distribution to confirm that the output is
always close to 0.25 (for the <code class="docutils literal notranslate"><span class="pre">P</span></code> matrix above).</p>
</section>
<section id="using-quantecons-routines">
<h3><span class="section-number">27.3.2. </span>Using QuantEcon’s routines<a class="headerlink" href="#using-quantecons-routines" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a> has routines for handling Markov chains, including simulation.</p>
<p>Here’s an illustration using the same <span class="math notranslate nohighlight">\(P\)</span> as the preceding example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.249298
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">simulate</span></code> routine is faster (because it is <a class="reference external" href="https://python-programming.quantecon.org/numba.html#numba-link">JIT compiled</a>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">time</span> mc_sample_path(P, ts_length=1_000_000) # Our homemade code version
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1.11 s, sys: 0 ns, total: 1.11 s
Wall time: 1.11 s
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 1, 1, ..., 1, 1, 0])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">time</span> mc.simulate(ts_length=1_000_000) # qe code version
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 14.1 ms, sys: 113 µs, total: 14.3 ms
Wall time: 13.9 ms
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 1, 1, ..., 1, 1, 1])
</pre></div>
</div>
</div>
</div>
<section id="adding-state-values-and-initial-conditions">
<h4><span class="section-number">27.3.2.1. </span>Adding state values and initial conditions<a class="headerlink" href="#adding-state-values-and-initial-conditions" title="Permalink to this heading">#</a></h4>
<p>If we wish to, we can provide a specification of state values to <code class="docutils literal notranslate"><span class="pre">MarkovChain</span></code>.</p>
<p>These state values can be integers, floats, or even strings.</p>
<p>The following code illustrates</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">state_values</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;unemployed&#39;</span><span class="p">,</span> <span class="s1">&#39;employed&#39;</span><span class="p">))</span>
<span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;employed&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;employed&#39;, &#39;employed&#39;, &#39;employed&#39;, &#39;employed&#39;], dtype=&#39;&lt;U10&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;unemployed&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;unemployed&#39;, &#39;employed&#39;, &#39;employed&#39;, &#39;employed&#39;], dtype=&#39;&lt;U10&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># Start at randomly chosen initial state</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;unemployed&#39;, &#39;employed&#39;, &#39;employed&#39;, &#39;unemployed&#39;], dtype=&#39;&lt;U10&#39;)
</pre></div>
</div>
</div>
</div>
<p>If we want to see indices rather than state values as outputs as  we can use</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span><span class="o">.</span><span class="n">simulate_indices</span><span class="p">(</span><span class="n">ts_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 1, 1, 1])
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="distributions-over-time">
<span id="mc-md"></span><h2><span class="section-number">27.4. </span>Distributions over time<a class="headerlink" href="#distributions-over-time" title="Permalink to this heading">#</a></h2>
<p>We learned that</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\{X_t\}\)</span> is a Markov chain with stochastic matrix <span class="math notranslate nohighlight">\(P\)</span></p></li>
<li><p>the distribution of <span class="math notranslate nohighlight">\(X_t\)</span> is known to be <span class="math notranslate nohighlight">\(\psi_t\)</span></p></li>
</ol>
<p>What then is the distribution of <span class="math notranslate nohighlight">\(X_{t+1}\)</span>, or, more generally, of <span class="math notranslate nohighlight">\(X_{t+m}\)</span>?</p>
<p>To answer this, we let <span class="math notranslate nohighlight">\(\psi_t\)</span> be the distribution of <span class="math notranslate nohighlight">\(X_t\)</span> for <span class="math notranslate nohighlight">\(t = 0, 1, 2, \ldots\)</span>.</p>
<p>Our first aim is to find <span class="math notranslate nohighlight">\(\psi_{t + 1}\)</span> given <span class="math notranslate nohighlight">\(\psi_t\)</span> and <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>To begin, pick any <span class="math notranslate nohighlight">\(y \in S\)</span>.</p>
<p>To get the probability of being at <span class="math notranslate nohighlight">\(y\)</span> tomorrow (at <span class="math notranslate nohighlight">\(t+1\)</span>), we account for
all ways this can happen and sum their probabilities.</p>
<p>This leads to</p>
<div class="math notranslate nohighlight">
\[
\mathbb P \{X_{t+1} = y \}
   = \sum_{x \in S} \mathbb P \{ X_{t+1} = y \, | \, X_t = x \}
               \cdot \mathbb P \{ X_t = x \}
\]</div>
<p>(We are using the <a class="reference external" href="https://en.wikipedia.org/wiki/Law_of_total_probability">law of total probability</a>.)</p>
<p>Rewriting this statement in terms of  marginal and conditional probabilities gives</p>
<div class="math notranslate nohighlight">
\[
    \psi_{t+1}(y) = \sum_{x \in S} P(x,y) \psi_t(x)
\]</div>
<p>There are <span class="math notranslate nohighlight">\(n\)</span> such equations, one for each <span class="math notranslate nohighlight">\(y \in S\)</span>.</p>
<p>If we think of <span class="math notranslate nohighlight">\(\psi_{t+1}\)</span> and <span class="math notranslate nohighlight">\(\psi_t\)</span> as row vectors, these <span class="math notranslate nohighlight">\(n\)</span> equations are summarized by the matrix expression</p>
<div class="math notranslate nohighlight" id="equation-fin-mc-fr">
<span class="eqno">(27.4)<a class="headerlink" href="#equation-fin-mc-fr" title="Permalink to this equation">#</a></span>\[\psi_{t+1} = \psi_t P\]</div>
<p>Thus, we postmultiply by <span class="math notranslate nohighlight">\(P\)</span> to move a distribution forward one unit of time.</p>
<p>By postmultiplying <span class="math notranslate nohighlight">\(m\)</span> times, we move a distribution forward <span class="math notranslate nohighlight">\(m\)</span> steps into the future.</p>
<p>Hence, iterating on <a class="reference internal" href="#equation-fin-mc-fr">(27.4)</a>, the expression <span class="math notranslate nohighlight">\(\psi_{t+m} = \psi_t P^m\)</span> is also valid — here <span class="math notranslate nohighlight">\(P^m\)</span> is the <span class="math notranslate nohighlight">\(m\)</span>-th power of <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>As a special case, we see that if <span class="math notranslate nohighlight">\(\psi_0\)</span> is the initial distribution from
which <span class="math notranslate nohighlight">\(X_0\)</span> is drawn, then <span class="math notranslate nohighlight">\(\psi_0 P^m\)</span> is the distribution of
<span class="math notranslate nohighlight">\(X_m\)</span>.</p>
<p>This is very important, so let’s repeat it</p>
<div class="math notranslate nohighlight" id="equation-mdfmc">
<span class="eqno">(27.5)<a class="headerlink" href="#equation-mdfmc" title="Permalink to this equation">#</a></span>\[X_0 \sim \psi_0 \quad \implies \quad X_m \sim \psi_0 P^m\]</div>
<p>The general rule is that post-multiplying a distribution by <span class="math notranslate nohighlight">\(P^m\)</span> shifts it forward <span class="math notranslate nohighlight">\(m\)</span> units of time.</p>
<p>Hence the following is also valid.</p>
<div class="math notranslate nohighlight" id="equation-mdfmc2">
<span class="eqno">(27.6)<a class="headerlink" href="#equation-mdfmc2" title="Permalink to this equation">#</a></span>\[X_t \sim \psi_t \quad \implies \quad X_{t+m} \sim \psi_t P^m\]</div>
<section id="multiple-step-transition-probabilities">
<span id="finite-mc-mstp"></span><h3><span class="section-number">27.4.1. </span>Multiple step transition probabilities<a class="headerlink" href="#multiple-step-transition-probabilities" title="Permalink to this heading">#</a></h3>
<p>We know that the probability of transitioning from <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\(y\)</span> in
one step is <span class="math notranslate nohighlight">\(P(x,y)\)</span>.</p>
<p>It turns out that the probability of transitioning from <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\(y\)</span> in
<span class="math notranslate nohighlight">\(m\)</span> steps is <span class="math notranslate nohighlight">\(P^m(x,y)\)</span>, the <span class="math notranslate nohighlight">\((x,y)\)</span>-th element of the
<span class="math notranslate nohighlight">\(m\)</span>-th power of <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>To see why, consider again <a class="reference internal" href="#equation-mdfmc2">(27.6)</a>, but now with a <span class="math notranslate nohighlight">\(\psi_t\)</span> that puts all probability on state <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Then <span class="math notranslate nohighlight">\(\psi_t\)</span> is a vector with <span class="math notranslate nohighlight">\(1\)</span> in position <span class="math notranslate nohighlight">\(x\)</span> and zero elsewhere.</p>
<p>Inserting this into <a class="reference internal" href="#equation-mdfmc2">(27.6)</a>, we see that, conditional on <span class="math notranslate nohighlight">\(X_t = x\)</span>, the distribution of <span class="math notranslate nohighlight">\(X_{t+m}\)</span> is the <span class="math notranslate nohighlight">\(x\)</span>-th row of <span class="math notranslate nohighlight">\(P^m\)</span>.</p>
<p>In particular</p>
<div class="math notranslate nohighlight">
\[
\mathbb P \{X_{t+m} = y \,|\, X_t = x \} = P^m(x, y) = (x, y) \text{-th element of } P^m
\]</div>
</section>
<section id="example-probability-of-recession">
<h3><span class="section-number">27.4.2. </span>Example: probability of recession<a class="headerlink" href="#example-probability-of-recession" title="Permalink to this heading">#</a></h3>
<p id="index-2">Recall the stochastic matrix <span class="math notranslate nohighlight">\(P\)</span> for recession and growth <a class="reference internal" href="#mc-eg2"><span class="std std-ref">considered above</span></a>.</p>
<p>Suppose that the current state is unknown — perhaps statistics are available only at the <em>end</em> of the current month.</p>
<p>We guess that the probability that the economy is in state <span class="math notranslate nohighlight">\(x\)</span> is <span class="math notranslate nohighlight">\(\psi_t(x)\)</span> at time t.</p>
<p>The probability of being in recession (either mild or severe) in 6 months time is given by</p>
<div class="math notranslate nohighlight">
\[
(\psi_t P^6)(1) + (\psi_t P^6)(2)
\]</div>
</section>
<section id="example-2-cross-sectional-distributions">
<span id="mc-eg1-1"></span><h3><span class="section-number">27.4.3. </span>Example 2: Cross-sectional distributions<a class="headerlink" href="#example-2-cross-sectional-distributions" title="Permalink to this heading">#</a></h3>
<p>The distributions we have been studying can be viewed either</p>
<ol class="arabic simple">
<li><p>as probabilities or</p></li>
<li><p>as cross-sectional frequencies that the Law of Large Numbers leads us to anticipate for large samples.</p></li>
</ol>
<p>To illustrate, recall our model of employment/unemployment dynamics for a given worker <a class="reference internal" href="#mc-eg1"><span class="std std-ref">discussed above</span></a>.</p>
<p>Consider a large population of workers, each of whose lifetime experience is
described by the specified dynamics, with each worker’s outcomes being
realizations of processes that are statistically independent of all other
workers’ processes.</p>
<p>Let <span class="math notranslate nohighlight">\(\psi_t\)</span> be the current <em>cross-sectional</em> distribution over <span class="math notranslate nohighlight">\(\{ 0, 1 \}\)</span>.</p>
<p>The cross-sectional distribution records fractions of workers employed and unemployed at a given moment t.</p>
<ul class="simple">
<li><p>For example, <span class="math notranslate nohighlight">\(\psi_t(0)\)</span> is the unemployment rate.</p></li>
</ul>
<p>What will the cross-sectional distribution be in 10 periods hence?</p>
<p>The answer is <span class="math notranslate nohighlight">\(\psi_t P^{10}\)</span>, where <span class="math notranslate nohighlight">\(P\)</span> is the stochastic matrix in
<a class="reference internal" href="#equation-p-unempemp">(27.1)</a>.</p>
<p>This is because each worker’s state evolves according to <span class="math notranslate nohighlight">\(P\)</span>, so
<span class="math notranslate nohighlight">\(\psi_t P^{10}\)</span> is a marginal distribution  for a single randomly selected
worker.</p>
<p>But when the sample is large, outcomes and probabilities are roughly equal (by an application of the Law
of Large Numbers).</p>
<p>So for a very large (tending to infinite) population,
<span class="math notranslate nohighlight">\(\psi_t P^{10}\)</span> also represents  fractions of workers in
each state.</p>
<p>This is exactly the cross-sectional distribution.</p>
</section>
</section>
<section id="stationary-distributions">
<span id="stationary"></span><h2><span class="section-number">27.5. </span>Stationary distributions<a class="headerlink" href="#stationary-distributions" title="Permalink to this heading">#</a></h2>
<p>As seen in <a class="reference internal" href="#equation-fin-mc-fr">(27.4)</a>, we can shift a distribution forward one
unit of time via postmultiplication by <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>Some distributions are invariant under this updating process — for example,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>
<span class="n">ψ</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">)</span>
<span class="n">ψ</span> <span class="o">@</span> <span class="n">P</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.25, 0.75])
</pre></div>
</div>
</div>
</div>
<p>Notice that <code class="docutils literal notranslate"><span class="pre">ψ</span> <span class="pre">&#64;</span> <span class="pre">P</span></code> is the same as <code class="docutils literal notranslate"><span class="pre">ψ</span></code>.</p>
<p>Such distributions are called <strong>stationary</strong> or <strong>invariant</strong>.</p>
<p id="mc-stat-dd">Formally, a distribution <span class="math notranslate nohighlight">\(\psi^*\)</span> on <span class="math notranslate nohighlight">\(S\)</span> is called <strong>stationary</strong> for <span class="math notranslate nohighlight">\(P\)</span> if <span class="math notranslate nohighlight">\(\psi^* P = \psi^* \)</span>.</p>
<p>Notice that, post-multiplying by <span class="math notranslate nohighlight">\(P\)</span>, we have <span class="math notranslate nohighlight">\(\psi^* P^2 = \psi^* P = \psi^*\)</span>.</p>
<p>Continuing in the same way leads to <span class="math notranslate nohighlight">\(\psi^* = \psi^* P^t\)</span> for all <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>This tells us an important fact: If the distribution of <span class="math notranslate nohighlight">\(\psi_0\)</span> is a stationary distribution, then <span class="math notranslate nohighlight">\(\psi_t\)</span> will have this same distribution for all <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>The following theorem is proved in Chapter 4 of <span id="id4">[<a class="reference internal" href="zreferences.html#id19" title="Thomas J Sargent and John Stachurski. Economic networks: theory and computation. arXiv preprint arXiv:2203.11972, 2023.">SS23</a>]</span> and numerous other sources.</p>
<div class="proof theorem admonition" id="unique_stat">
<p class="admonition-title"><span class="caption-number">Theorem 27.1 </span></p>
<section class="theorem-content" id="proof-content">
<p>Every stochastic matrix <span class="math notranslate nohighlight">\(P\)</span> has at least one stationary distribution.</p>
</section>
</div><p>Note that there can be many stationary distributions corresponding to a given
stochastic matrix <span class="math notranslate nohighlight">\(P\)</span>.</p>
<ul class="simple">
<li><p>For example, if <span class="math notranslate nohighlight">\(P\)</span> is the identity matrix, then all distributions on <span class="math notranslate nohighlight">\(S\)</span> are stationary.</p></li>
</ul>
<p>To get uniqueness, we need the Markov chain to “mix around,” so that the state
doesn’t get stuck in some part of the state space.</p>
<p>This gives some intuition for the following theorem.</p>
<div class="proof theorem admonition" id="mc_po_conv_thm">
<p class="admonition-title"><span class="caption-number">Theorem 27.2 </span></p>
<section class="theorem-content" id="proof-content">
<p>If <span class="math notranslate nohighlight">\(P\)</span> is everywhere positive, then <span class="math notranslate nohighlight">\(P\)</span> has exactly one stationary
distribution.</p>
</section>
</div><p>We will come back to this when we introduce irreducibility in the <a class="reference internal" href="markov_chains_II.html"><span class="doc">next lecture</span></a> on Markov chains.</p>
<section id="example">
<h3><span class="section-number">27.5.1. </span>Example<a class="headerlink" href="#example" title="Permalink to this heading">#</a></h3>
<p>Recall our model of the employment/unemployment dynamics of a particular worker <a class="reference internal" href="#mc-eg1"><span class="std std-ref">discussed above</span></a>.</p>
<p>If <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span> and <span class="math notranslate nohighlight">\(\beta \in (0,1)\)</span>, then the transition matrix is everywhere positive.</p>
<p>Let <span class="math notranslate nohighlight">\(\psi^* = (p, 1-p)\)</span> be the stationary distribution, so that <span class="math notranslate nohighlight">\(p\)</span>
corresponds to unemployment (state 0).</p>
<p>Using <span class="math notranslate nohighlight">\(\psi^* = \psi^* P\)</span> and a bit of algebra yields</p>
<div class="math notranslate nohighlight">
\[
    p = \frac{\beta}{\alpha + \beta}
\]</div>
<p>This is, in some sense, a steady state probability of unemployment.</p>
<p>Not surprisingly it tends to zero as <span class="math notranslate nohighlight">\(\beta \to 0\)</span>, and to one as <span class="math notranslate nohighlight">\(\alpha \to 0\)</span>.</p>
</section>
<section id="calculating-stationary-distributions">
<h3><span class="section-number">27.5.2. </span>Calculating stationary distributions<a class="headerlink" href="#calculating-stationary-distributions" title="Permalink to this heading">#</a></h3>
<p>A stable algorithm for computing stationary distributions is implemented in <a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a>.</p>
<p>Here’s an example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]]</span>

<span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span>  <span class="c1"># Show all stationary distributions</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.25, 0.75]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="asymptotic-stationarity">
<h3><span class="section-number">27.5.3. </span>Asymptotic stationarity<a class="headerlink" href="#asymptotic-stationarity" title="Permalink to this heading">#</a></h3>
<p>Consider an everywhere positive stochastic matrix with unique stationary distribution <span class="math notranslate nohighlight">\(\psi^*\)</span>.</p>
<p>Sometimes the distribution <span class="math notranslate nohighlight">\(\psi_t = \psi_0 P^t\)</span> of <span class="math notranslate nohighlight">\(X_t\)</span> converges to <span class="math notranslate nohighlight">\(\psi^*\)</span> regardless of <span class="math notranslate nohighlight">\(\psi_0\)</span>.</p>
<p>For example, we have the following result</p>
<div class="proof theorem admonition" id="theorem-2">
<span id="strict-stationary"></span><p class="admonition-title"><span class="caption-number">Theorem 27.3 </span></p>
<section class="theorem-content" id="proof-content">
<p>Theorem: If there exists an integer <span class="math notranslate nohighlight">\(m\)</span> such that all entries of <span class="math notranslate nohighlight">\(P^m\)</span> are
strictly positive, with unique stationary distribution <span class="math notranslate nohighlight">\(\psi^*\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
    \psi_0 P^t \to \psi^*
    \quad \text{ as } t \to \infty
\]</div>
</section>
</div><p>See, for example, <span id="id5">[<a class="reference internal" href="zreferences.html#id19" title="Thomas J Sargent and John Stachurski. Economic networks: theory and computation. arXiv preprint arXiv:2203.11972, 2023.">SS23</a>]</span> Chapter 4.</p>
<section id="example-hamiltons-chain">
<span id="hamilton"></span><h4><span class="section-number">27.5.3.1. </span>Example: Hamilton’s chain<a class="headerlink" href="#example-hamiltons-chain" title="Permalink to this heading">#</a></h4>
<p>Hamilton’s chain satisfies the conditions of the theorem because <span class="math notranslate nohighlight">\(P^2\)</span> is everywhere positive:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.971</span><span class="p">,</span> <span class="mf">0.029</span><span class="p">,</span> <span class="mf">0.000</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.145</span><span class="p">,</span> <span class="mf">0.778</span><span class="p">,</span> <span class="mf">0.077</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.000</span><span class="p">,</span> <span class="mf">0.508</span><span class="p">,</span> <span class="mf">0.492</span><span class="p">]])</span>
<span class="n">P</span> <span class="o">@</span> <span class="n">P</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.947046, 0.050721, 0.002233],
       [0.253605, 0.648605, 0.09779 ],
       [0.07366 , 0.64516 , 0.28118 ]])
</pre></div>
</div>
</div>
</div>
<p>Let’s pick an initial distribution <span class="math notranslate nohighlight">\(\psi_0\)</span> and trace out the sequence of distributions <span class="math notranslate nohighlight">\(\psi_0 P^t\)</span> for <span class="math notranslate nohighlight">\(t = 0, 1, 2, \ldots\)</span></p>
<p>First, we write a function to iterate the sequence of distributions for <code class="docutils literal notranslate"><span class="pre">ts_length</span></code> period</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">iterate_ψ</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">ψ_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">ts_length</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">ψ</span> <span class="o">=</span> <span class="n">ψ_0</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ts_length</span><span class="p">):</span>
        <span class="n">ψ_t</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">ψ</span>
        <span class="n">ψ</span> <span class="o">=</span> <span class="n">ψ</span> <span class="o">@</span> <span class="n">P</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ψ_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we plot the sequence</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ψ_0</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>        <span class="c1"># Initial condition</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">zlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
       <span class="n">xticks</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">),</span>
       <span class="n">yticks</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">),</span>
       <span class="n">zticks</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">))</span>

<span class="n">ψ_t</span> <span class="o">=</span> <span class="n">iterate_ψ</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">ψ_t</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">ψ_t</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">ψ_t</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">210</span><span class="p">)</span>

<span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">ψ_star</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">ψ_star</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ψ_star</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ψ_star</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/0e4989eb7095179ccc3e9119167d1d43c60ea839ccd9b751f702011b2b0e8b5c.png"><img alt="_images/0e4989eb7095179ccc3e9119167d1d43c60ea839ccd9b751f702011b2b0e8b5c.png" src="_images/0e4989eb7095179ccc3e9119167d1d43c60ea839ccd9b751f702011b2b0e8b5c.png" style="width: 80%;" /></a>
</div>
</div>
<p>Here</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P\)</span> is the stochastic matrix for recession and growth <a class="reference internal" href="#mc-eg2"><span class="std std-ref">considered above</span></a>.</p></li>
<li><p>The highest red dot is an arbitrarily chosen initial marginal probability distribution  <span class="math notranslate nohighlight">\(\psi_0\)</span>, represented as a vector in <span class="math notranslate nohighlight">\(\mathbb R^3\)</span>.</p></li>
<li><p>The other red dots are the marginal distributions <span class="math notranslate nohighlight">\(\psi_0 P^t\)</span> for <span class="math notranslate nohighlight">\(t = 1, 2, \ldots\)</span>.</p></li>
<li><p>The black dot is <span class="math notranslate nohighlight">\(\psi^*\)</span>.</p></li>
</ul>
<p>You might like to try experimenting with different initial conditions.</p>
</section>
<section id="an-alternative-illustration">
<h4><span class="section-number">27.5.3.2. </span>An alternative illustration<a class="headerlink" href="#an-alternative-illustration" title="Permalink to this heading">#</a></h4>
<p>We can show this in a slightly different way by focusing on the probability that <span class="math notranslate nohighlight">\(\psi_t\)</span> puts on each state.</p>
<p>First, we write a function to draw initial distributions <span class="math notranslate nohighlight">\(\psi_0\)</span> of size <code class="docutils literal notranslate"><span class="pre">num_distributions</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_initial_values</span><span class="p">(</span><span class="n">num_distributions</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">ψ_0s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">num_distributions</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_distributions</span><span class="p">):</span>
        <span class="n">draws</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10_000_000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

        <span class="c1"># Scale them so that they add up into 1</span>
        <span class="n">ψ_0s</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">draws</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">draws</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">ψ_0s</span>
</pre></div>
</div>
</div>
</div>
<p>We then write a function to plot the dynamics of  <span class="math notranslate nohighlight">\((\psi_0 P^t)(i)\)</span> as <span class="math notranslate nohighlight">\(t\)</span> gets large, for each state <span class="math notranslate nohighlight">\(i\)</span> with different initial distributions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_distribution</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">,</span> <span class="n">num_distributions</span><span class="p">):</span>

    <span class="c1"># Get parameters of transition matrix</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">ψ_star</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1">## Draw the plot</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>

    <span class="n">ψ_0s</span> <span class="o">=</span> <span class="n">generate_initial_values</span><span class="p">(</span><span class="n">num_distributions</span><span class="p">)</span>

    <span class="c1"># Get the path for each starting value</span>
    <span class="k">for</span> <span class="n">ψ_0</span> <span class="ow">in</span> <span class="n">ψ_0s</span><span class="p">:</span>
        <span class="n">ψ_t</span> <span class="o">=</span> <span class="n">iterate_ψ</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">)</span>

        <span class="c1"># Obtain and plot distributions at each state</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">),</span> <span class="n">ψ_t</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Add labels</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">ψ_star</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span>
                        <span class="n">label</span> <span class="o">=</span> <span class="sa">fr</span><span class="s1">&#39;$\psi^*(</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">)$&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;$\psi_t(</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">)$&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure shows</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the number of iterations</span>
<span class="c1"># and initial distributions</span>
<span class="n">ts_length</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">num_distributions</span> <span class="o">=</span> <span class="mi">25</span>

<span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.971</span><span class="p">,</span> <span class="mf">0.029</span><span class="p">,</span> <span class="mf">0.000</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.145</span><span class="p">,</span> <span class="mf">0.778</span><span class="p">,</span> <span class="mf">0.077</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.000</span><span class="p">,</span> <span class="mf">0.508</span><span class="p">,</span> <span class="mf">0.492</span><span class="p">]])</span>

<span class="n">plot_distribution</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">,</span> <span class="n">num_distributions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/02dab88c15577524d0822985c06f7d62f8747bcebe4b94a7a29fa90ca9aeefa7.png"><img alt="_images/02dab88c15577524d0822985c06f7d62f8747bcebe4b94a7a29fa90ca9aeefa7.png" src="_images/02dab88c15577524d0822985c06f7d62f8747bcebe4b94a7a29fa90ca9aeefa7.png" style="width: 80%;" /></a>
</div>
</div>
<p>The convergence to <span class="math notranslate nohighlight">\(\psi^*\)</span> holds for different initial distributions.</p>
</section>
<section id="example-failure-of-convergence">
<h4><span class="section-number">27.5.3.3. </span>Example: Failure of convergence<a class="headerlink" href="#example-failure-of-convergence" title="Permalink to this heading">#</a></h4>
<p>In the case of a periodic chain, with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P = 
\begin{bmatrix}
    0 &amp; 1 \\
    1 &amp; 0 \\
\end{bmatrix}
\end{split}\]</div>
<p>we find the distribution oscillates</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="n">ts_length</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">num_distributions</span> <span class="o">=</span> <span class="mi">30</span>

<span class="n">plot_distribution</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">,</span> <span class="n">num_distributions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/8dd35b0b449a612d8a208f159db1d3fbbbe82c36b6fadf7744e692d3deb0f008.png"><img alt="_images/8dd35b0b449a612d8a208f159db1d3fbbbe82c36b6fadf7744e692d3deb0f008.png" src="_images/8dd35b0b449a612d8a208f159db1d3fbbbe82c36b6fadf7744e692d3deb0f008.png" style="width: 80%;" /></a>
</div>
</div>
<p>Indeed, this <span class="math notranslate nohighlight">\(P\)</span> fails our asymptotic stationarity condition, since, as you can
verify, <span class="math notranslate nohighlight">\(P^t\)</span> is not everywhere positive for any <span class="math notranslate nohighlight">\(t\)</span>.</p>
</section>
</section>
</section>
<section id="computing-expectations">
<span id="finite-mc-expec"></span><h2><span class="section-number">27.6. </span>Computing expectations<a class="headerlink" href="#computing-expectations" title="Permalink to this heading">#</a></h2>
<p id="index-3">We sometimes want to  compute mathematical  expectations of functions of <span class="math notranslate nohighlight">\(X_t\)</span> of the form</p>
<div class="math notranslate nohighlight" id="equation-mc-une">
<span class="eqno">(27.7)<a class="headerlink" href="#equation-mc-une" title="Permalink to this equation">#</a></span>\[\mathbb E [ h(X_t) ]\]</div>
<p>and conditional expectations such as</p>
<div class="math notranslate nohighlight" id="equation-mc-cce">
<span class="eqno">(27.8)<a class="headerlink" href="#equation-mc-cce" title="Permalink to this equation">#</a></span>\[\mathbb E [ h(X_{t + k})  \mid X_t = x]\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\{X_t\}\)</span> is a Markov chain generated by <span class="math notranslate nohighlight">\(n \times n\)</span> stochastic matrix <span class="math notranslate nohighlight">\(P\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(h\)</span> is a given function, which, in terms of matrix
algebra, we’ll think of as the column vector</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
h =
\begin{bmatrix}
    h(x_1) \\
    \vdots \\
    h(x_n)
\end{bmatrix}.
\end{split}\]</div>
<p>Computing the unconditional expectation <a class="reference internal" href="#equation-mc-une">(27.7)</a> is easy.</p>
<p>We just sum over the marginal  distribution  of <span class="math notranslate nohighlight">\(X_t\)</span> to get</p>
<div class="math notranslate nohighlight">
\[
\mathbb E [ h(X_t) ]
= \sum_{x \in S} (\psi P^t)(x) h(x)
\]</div>
<p>Here <span class="math notranslate nohighlight">\(\psi\)</span> is the distribution of <span class="math notranslate nohighlight">\(X_0\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(\psi\)</span> and hence <span class="math notranslate nohighlight">\(\psi P^t\)</span> are row vectors, we can also
write this as</p>
<div class="math notranslate nohighlight">
\[
\mathbb E [ h(X_t) ]
=  \psi P^t h
\]</div>
<p>For the conditional expectation <a class="reference internal" href="#equation-mc-cce">(27.8)</a>, we need to sum over
the conditional distribution of <span class="math notranslate nohighlight">\(X_{t + k}\)</span> given <span class="math notranslate nohighlight">\(X_t = x\)</span>.</p>
<p>We already know that this is <span class="math notranslate nohighlight">\(P^k(x, \cdot)\)</span>, so</p>
<div class="math notranslate nohighlight" id="equation-mc-cce2">
<span class="eqno">(27.9)<a class="headerlink" href="#equation-mc-cce2" title="Permalink to this equation">#</a></span>\[\mathbb E [ h(X_{t + k})  \mid X_t = x]
= (P^k h)(x)\]</div>
<section id="expectations-of-geometric-sums">
<h3><span class="section-number">27.6.1. </span>Expectations of geometric sums<a class="headerlink" href="#expectations-of-geometric-sums" title="Permalink to this heading">#</a></h3>
<p>Sometimes we want to compute the mathematical expectation of a geometric sum, such as
<span class="math notranslate nohighlight">\(\sum_t \beta^t h(X_t)\)</span>.</p>
<p>In view of the preceding discussion, this is</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}
    \left[
        \sum_{j=0}^\infty \beta^j h(X_{t+j}) \mid X_t
        = x
    \right]
    = x + \beta (Ph)(x) + \beta^2 (P^2 h)(x) + \cdots
\]</div>
<p>By the <a class="reference internal" href="eigen_I.html#la-neumann"><span class="std std-ref">Neumann series lemma</span></a>, this sum can be calculated using</p>
<div class="math notranslate nohighlight">
\[
    I + \beta P + \beta^2 P^2 + \cdots = (I - \beta P)^{-1}
\]</div>
<p>The vector <span class="math notranslate nohighlight">\(P^k h\)</span> stores the conditional expectation <span class="math notranslate nohighlight">\(\mathbb E [ h(X_{t + k})  \mid X_t = x]\)</span> over all <span class="math notranslate nohighlight">\(x\)</span>.</p>
<div class="exercise admonition" id="mc1_ex_1">

<p class="admonition-title"><span class="caption-number">Exercise 27.1 </span></p>
<section id="exercise-content">
<p>Imam and Temple <span id="id6">[<a class="reference internal" href="zreferences.html#id284" title="Patrick Imam and Jonathan RW Temple. Political institutions and output collapses. IMF Working Paper, 2023.">IT23</a>]</span> used a three-state transition matrix to describe the transition of three states of a regime: growth, stagnation, and collapse</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P :=
\begin{bmatrix}
    0.68 &amp; 0.12 &amp; 0.20 \\
    0.50 &amp; 0.24 &amp; 0.26 \\
    0.36 &amp; 0.18 &amp; 0.46
\end{bmatrix}
\end{split}\]</div>
<p>where rows, from top to down, correspond to growth, stagnation, and collapse.</p>
<p>In this exercise,</p>
<ol class="arabic simple">
<li><p>visualize the transition matrix and show this process is asymptotically stationary</p></li>
<li><p>calculate the stationary distribution using simulations</p></li>
<li><p>visualize the dynamics of  <span class="math notranslate nohighlight">\((\psi_0 P^t)(i)\)</span> where <span class="math notranslate nohighlight">\(t \in 0, ..., 25\)</span> and compare the convergent path with the previous transition matrix</p></li>
</ol>
<p>Compare your solution to the paper.</p>
</section>
</div>
<div class="solution dropdown admonition" id="markov_chains_I-solution-4">

<p class="admonition-title">Solution to<a class="reference internal" href="#mc1_ex_1"> Exercise 27.1</a></p>
<section id="solution-content">
<p>Solution 1:</p>
<img alt="_images/Temple.png" class="align-center" id="mc-temple" src="_images/Temple.png" />
<p>Since the matrix is everywhere positive, there is a unique stationary distribution.</p>
<p>Solution 2:</p>
<p>One simple way to calculate the stationary distribution is to take the power of the transition matrix as we have shown before</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.68</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.20</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.24</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.18</span><span class="p">,</span> <span class="mf">0.46</span><span class="p">]])</span>
<span class="n">P_power</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">P_power</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.56145769, 0.15565164, 0.28289067],
       [0.56145769, 0.15565164, 0.28289067],
       [0.56145769, 0.15565164, 0.28289067]])
</pre></div>
</div>
</div>
</div>
<p>Note that rows of the transition matrix converge to the stationary distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ψ_star_p</span> <span class="o">=</span> <span class="n">P_power</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ψ_star_p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.56145769, 0.15565164, 0.28289067])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">ψ_star</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ψ_star</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.56145769, 0.15565164, 0.28289067])
</pre></div>
</div>
</div>
</div>
<p>Solution 3:</p>
<p>We find the distribution <span class="math notranslate nohighlight">\(\psi\)</span> converges to the stationary distribution more quickly compared to the <a class="reference internal" href="#hamilton"><span class="std std-ref">hamilton’s chain</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ts_length</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_distributions</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">plot_distribution</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">,</span> <span class="n">num_distributions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/4ddfbd1affc9845851d6e7083dc26b89da818d9e3a7fea9760006024c7e24391.png"><img alt="_images/4ddfbd1affc9845851d6e7083dc26b89da818d9e3a7fea9760006024c7e24391.png" src="_images/4ddfbd1affc9845851d6e7083dc26b89da818d9e3a7fea9760006024c7e24391.png" style="width: 80%;" /></a>
</div>
</div>
<p>In fact, the rate of convergence is governed by <a class="reference internal" href="eigen_I.html#eigen"><span class="std std-ref">eigenvalues</span></a> <span id="id7">[<a class="reference internal" href="zreferences.html#id19" title="Thomas J Sargent and John Stachurski. Economic networks: theory and computation. arXiv preprint arXiv:2203.11972, 2023.">SS23</a>]</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P_eigenvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">P_eigenvals</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.        , 0.28219544, 0.09780456])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P_hamilton</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.971</span><span class="p">,</span> <span class="mf">0.029</span><span class="p">,</span> <span class="mf">0.000</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.145</span><span class="p">,</span> <span class="mf">0.778</span><span class="p">,</span> <span class="mf">0.077</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.000</span><span class="p">,</span> <span class="mf">0.508</span><span class="p">,</span> <span class="mf">0.492</span><span class="p">]])</span>

<span class="n">hamilton_eigenvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">P_hamilton</span><span class="p">)</span>
<span class="n">hamilton_eigenvals</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.        , 0.85157412, 0.38942588])
</pre></div>
</div>
</div>
</div>
<p>More specifically, it is governed by the spectral gap, the difference between the largest and the second largest eigenvalue.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sp_gap_P</span> <span class="o">=</span> <span class="n">P_eigenvals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">P_eigenvals</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sp_gap_hamilton</span> <span class="o">=</span> <span class="n">hamilton_eigenvals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">hamilton_eigenvals</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">sp_gap_P</span> <span class="o">&gt;</span> <span class="n">sp_gap_hamilton</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>We will come back to this when we discuss <a class="reference internal" href="eigen_II.html#spec-markov"><span class="std std-ref">spectral theory</span></a>.</p>
</section>
</div>
<div class="exercise admonition" id="mc1_ex_2">

<p class="admonition-title"><span class="caption-number">Exercise 27.2 </span></p>
<section id="exercise-content">
<p>We discussed the six-state transition matrix estimated by Imam &amp; Temple <span id="id8">[<a class="reference internal" href="zreferences.html#id284" title="Patrick Imam and Jonathan RW Temple. Political institutions and output collapses. IMF Working Paper, 2023.">IT23</a>]</span> <a class="reference internal" href="#mc-eg3"><span class="std std-ref">before</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DG&#39;</span><span class="p">,</span> <span class="s1">&#39;DC&#39;</span><span class="p">,</span> <span class="s1">&#39;NG&#39;</span><span class="p">,</span> <span class="s1">&#39;NC&#39;</span><span class="p">,</span> <span class="s1">&#39;AG&#39;</span><span class="p">,</span> <span class="s1">&#39;AC&#39;</span><span class="p">]</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
     <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">]]</span>
</pre></div>
</div>
<p>In this exercise,</p>
<ol class="arabic simple">
<li><p>show this process is asymptotically stationary without simulation</p></li>
<li><p>simulate and visualize the dynamics starting with a uniform distribution across states (each state will have a probability of 1/6)</p></li>
<li><p>change the initial distribution to P(DG) = 1, while all other states have a probability of 0</p></li>
</ol>
</section>
</div>
<div class="solution dropdown admonition" id="markov_chains_I-solution-6">

<p class="admonition-title">Solution to<a class="reference internal" href="#mc1_ex_2"> Exercise 27.2</a></p>
<section id="solution-content">
<p>Solution 1:</p>
<p>Although <span class="math notranslate nohighlight">\(P\)</span> is not every positive, <span class="math notranslate nohighlight">\(P^m\)</span> when <span class="math notranslate nohighlight">\(m=3\)</span> is everywhere positive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">]])</span>

<span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.764927, 0.133481, 0.085949, 0.011481, 0.002956, 0.001206],
       [0.658861, 0.131559, 0.161367, 0.031703, 0.011296, 0.005214],
       [0.291394, 0.057788, 0.439702, 0.113408, 0.062707, 0.035001],
       [0.272459, 0.051361, 0.365075, 0.132207, 0.108152, 0.070746],
       [0.064129, 0.012533, 0.232875, 0.154385, 0.299243, 0.236835],
       [0.072865, 0.014081, 0.244139, 0.160905, 0.265846, 0.242164]])
</pre></div>
</div>
</div>
</div>
<p>So it satisfies the requirement.</p>
<p>Solution 2:</p>
<p>We find the distribution <span class="math notranslate nohighlight">\(\psi\)</span> converges to the stationary distribution quickly regardless of the initial distributions</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ts_length</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">num_distributions</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DG&#39;</span><span class="p">,</span> <span class="s1">&#39;DC&#39;</span><span class="p">,</span> <span class="s1">&#39;NG&#39;</span><span class="p">,</span> <span class="s1">&#39;NC&#39;</span><span class="p">,</span> <span class="s1">&#39;AG&#39;</span><span class="p">,</span> <span class="s1">&#39;AC&#39;</span><span class="p">]</span>

<span class="c1"># Get parameters of transition matrix</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">mc</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">MarkovChain</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">ψ_star</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ψ_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="o">/</span><span class="mi">6</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)],</span>
                <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]])</span>
<span class="c1">## Draw the plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">ψ_t</span> <span class="o">=</span> <span class="n">iterate_ψ</span><span class="p">(</span><span class="n">ψ_0</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">P</span><span class="p">,</span> <span class="n">ts_length</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ψ_t</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">ψ_star</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;$\psi_t(</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">)$&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;$\psi_t$&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/2391959e04c76f6170a32cf28be9793c33ded935db28fe1d26eb3f63cc057798.png"><img alt="_images/2391959e04c76f6170a32cf28be9793c33ded935db28fe1d26eb3f63cc057798.png" src="_images/2391959e04c76f6170a32cf28be9793c33ded935db28fe1d26eb3f63cc057798.png" style="width: 80%;" /></a>
</div>
</div>
</section>
</div>
<div class="exercise admonition" id="mc1_ex_3">

<p class="admonition-title"><span class="caption-number">Exercise 27.3 </span></p>
<section id="exercise-content">
<p>Prove the following: If <span class="math notranslate nohighlight">\(P\)</span> is a stochastic matrix, then so is the <span class="math notranslate nohighlight">\(k\)</span>-th
power <span class="math notranslate nohighlight">\(P^k\)</span> for all <span class="math notranslate nohighlight">\(k \in \mathbb N\)</span>.</p>
</section>
</div>
<div class="solution dropdown admonition" id="markov_chains_I-solution-8">

<p class="admonition-title">Solution to<a class="reference internal" href="#mc1_ex_3"> Exercise 27.3</a></p>
<section id="solution-content">
<p>Suppose that <span class="math notranslate nohighlight">\(P\)</span> is stochastic and, moreover, that <span class="math notranslate nohighlight">\(P^k\)</span> is
stochastic for some integer <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>We will prove that <span class="math notranslate nohighlight">\(P^{k+1} = P P^k\)</span> is also stochastic.</p>
<p>(We are doing proof by induction — we assume the claim is true at <span class="math notranslate nohighlight">\(k\)</span> and
now prove it is true at <span class="math notranslate nohighlight">\(k+1\)</span>.)</p>
<p>To see this, observe that, since <span class="math notranslate nohighlight">\(P^k\)</span> is stochastic and the product of
nonnegative matrices is nonnegative, <span class="math notranslate nohighlight">\(P^{k+1} = P P^k\)</span> is nonnegative.</p>
<p>Also, if <span class="math notranslate nohighlight">\(\mathbf 1\)</span> is a column vector of ones, then, since <span class="math notranslate nohighlight">\(P^k\)</span> is stochastic we
have <span class="math notranslate nohighlight">\(P^k \mathbf 1 = \mathbf 1\)</span> (rows sum to one).</p>
<p>Therefore <span class="math notranslate nohighlight">\(P^{k+1} \mathbf 1 = P P^k \mathbf 1 = P \mathbf 1 = \mathbf 1\)</span></p>
<p>The proof is done.</p>
</section>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="about.html">
   1. About These Lectures
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Economic Data
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="long_run_growth.html">
   2. Long-Run Growth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="business_cycle.html">
   3. Business Cycles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="inflation_history.html">
   4. Price Level Histories
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="inequality.html">
   5. Income and Wealth Inequality
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Essential Tools
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="complex_and_trig.html">
   6. Complex Numbers and Trigonometry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_equations.html">
   7. Linear Equations and Matrix Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="eigen_I.html">
   8. Eigenvalues and Eigenvectors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="intro_supply_demand.html">
   9. Introduction to Supply and Demand
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear Dynamics
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="pv.html">
   10. Present Values
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cons_smooth.html">
   11. Consumption Smoothing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="equalizing_difference.html">
   12. Equalizing Difference Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cagan_ree.html">
   13. A Monetarist Theory of  Price Levels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cagan_adaptive.html">
   14. A Monetarist Theory of Price Levels with Adaptive Expectations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="geom_series.html">
   15. Geometric Series for Elementary Economics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probability and Distributions
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="prob_dist.html">
   16. Distributions and Probabilities
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lln_clt.html">
   17. LLN and CLT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="monte_carlo.html">
   18. Monte Carlo and Option Pricing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="heavy_tails.html">
   19. Heavy-Tailed Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="schelling.html">
   20. Racial Segregation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Nonlinear Dynamics
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="solow.html">
   21. The Solow-Swan Growth Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scalar_dynam.html">
   22. Dynamics in One Dimension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cobweb.html">
   23. The Cobweb Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="olg.html">
   24. The Overlapping Generations Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="commod_price.html">
   25. Commodity Prices
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Stochastic Dynamics
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ar1_processes.html">
   26. AR1 Processes
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   27. Markov Chains: Basic Concepts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markov_chains_II.html">
   28. Markov Chains: Irreducibility and Ergodicity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="time_series_with_matrices.html">
   29. Univariate Time Series with Matrix Algebra
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Optimization
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lp_intro.html">
   30. Linear Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="short_path.html">
   31. Shortest Paths
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Modeling in Higher Dimensions
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="eigen_II.html">
   32. The Perron-Frobenius Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="input_output.html">
   33. Input-Output Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lake_model.html">
   34. A Lake Model of Employment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="networks.html">
   35. Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Markets and Competitive Equilibrium
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="supply_demand_multiple_goods.html">
   36. Supply and Demand with Many Goods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="supply_demand_heterogeneity.html">
   37. Market Equilibrium with Heterogeneity
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Estimation
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="simple_linear_regression.html">
   38. Simple Linear Regression Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mle.html">
   39. Maximum Likelihood Estimation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   40. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   41. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="status.html">
   42. Execution Statistics
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                </ul>

                <ul class="qe-toolbar__links">
                    <li class="btn__search">
                        <form action="search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" accesskey="k">
                            <i data-feather="search" id="search-icon"></i>
                        </form>
                    </li>
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="/_notebooks/markov_chains_I.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li class="download-pdf" id="downloadButton"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python-intro/blob/main/lectures/markov_chains_I.md" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="/_pdf/quantecon-python-intro.pdf" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://mybinder.org/v2/gh/QuantEcon/lecture-python-intro.notebooks/master?urlpath=tree/markov_chains_I.ipynb">BinderHub</option>
                
                    <option value="https://colab.research.google.com/github/QuantEcon/lecture-python-intro.notebooks/blob/master/markov_chains_I.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-python-intro.notebooks" data-urlpath="tree/lecture-python-intro.notebooks/markov_chains_I.ipynb" data-branch=master>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://colab.research.google.com/github/QuantEcon/lecture-python-intro.notebooks/blob/master/markov_chains_I.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "markov_chains_I";
                const repoURL = "https://github.com/QuantEcon/lecture-python-intro.notebooks";
                const urlPath = "tree/lecture-python-intro.notebooks/markov_chains_I.ipynb";
                const branch = "master"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>