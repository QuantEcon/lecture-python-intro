{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfe0a0b",
   "metadata": {},
   "source": [
    "# Spectral Theory\n",
    "\n",
    "\n",
    "<a id='index-0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3b14d",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Spectral Theory](#Spectral-Theory)  \n",
    "  - [Nonnegative matrices](#Nonnegative-matrices)  \n",
    "  - [The Neumann Series Lemma](#The-Neumann-Series-Lemma)  \n",
    "  - [Exercises](#Exercises)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f9299d",
   "metadata": {},
   "source": [
    "In addition to what’s in Anaconda, this lecture will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45b989",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "!pip install quantecon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d48b25",
   "metadata": {},
   "source": [
    "In this lecture we will begin with the foundational concepts in spectral theory.\n",
    "\n",
    "Then we will explore the Perron-Frobenius Theorem and the Neumann Series Lemma, and connect them to applications in Markov chains and networks.\n",
    "\n",
    "We will use the following imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1420b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "import scipy as sp\n",
    "import quantecon as qe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6447ee",
   "metadata": {},
   "source": [
    "## Nonnegative matrices\n",
    "\n",
    "Often, in economics, the matrix that we are dealing with is nonnegative.\n",
    "\n",
    "Nonnegative matrices have several special and useful properties.\n",
    "\n",
    "In this section we will discuss some of them — in particular, the connection\n",
    "between nonnegativity and eigenvalues.\n",
    "\n",
    "Let $ a^{k}_{ij} $ be element $ (i,j) $ of $ A^k $.\n",
    "\n",
    "An $ n \\times m $ matrix $ A $ is called **nonnegative** if every element of $ A $\n",
    "is nonnegative, i.e., $ a_{ij} \\geq 0 $ for every $ i,j $.\n",
    "\n",
    "We denote this as $ A \\geq 0 $.\n",
    "\n",
    "\n",
    "<a id='irreducible'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f8f73",
   "metadata": {},
   "source": [
    "### Irreducible matrices\n",
    "\n",
    "We introduced irreducible matrices in the [Markov chain lecture](https://intro.quantecon.org/markov_chains_II.html#mc-irreducible).\n",
    "\n",
    "Here we generalize this concept:\n",
    "\n",
    "An $ n \\times n $ matrix $ A $ is called irreducible if, for each $ i,j $ with $ 1 \\leq i, j \\leq n $, there exists a $ k \\geq 0 $ such that $ a^{k}_{ij} > 0 $.\n",
    "\n",
    "A matrix $ A $ that is not irreducible is called reducible.\n",
    "\n",
    "Here are some examples to illustrate this further.\n",
    "\n",
    "1. $ A = \\begin{bmatrix} 0.5 & 0.1 \\\\ 0.2 & 0.2 \\end{bmatrix} $ is irreducible since $ a_{ij}>0 $ for all $ (i,j) $.  \n",
    "1. $ A = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} $ is irreducible since $ a_{12},a_{21} >0 $ and $ a^{2}_{11},a^{2}_{22} >0 $.  \n",
    "1. $ A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} $ is reducible since $ A^k = A $ for all $ k \\geq 0 $ and thus\n",
    "  $ a^{k}_{12},a^{k}_{21} = 0 $ for all $ k \\geq 0 $.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f822b",
   "metadata": {},
   "source": [
    "### Primitive matrices\n",
    "\n",
    "Let $ A $ be a square nonnegative matrix and let $ A^k $ be the $ k^{th} $ power of $ A $.\n",
    "\n",
    "A matrix is called **primitive** if there exists a $ k \\in \\mathbb{N} $ such that $ A^k $ is everywhere positive.\n",
    "\n",
    "It means that $ A $ is called primitive if there is an integer $ k \\geq 0 $ such that $ a^{k}_{ij} > 0 $ for *all* $ (i,j) $.\n",
    "\n",
    "We can see that if a matrix is primitive, then it implies the matrix is irreducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341b148",
   "metadata": {},
   "source": [
    "### Left eigenvectors\n",
    "\n",
    "We previously discussed right (ordinary) eigenvectors $ Av = \\lambda v $.\n",
    "\n",
    "Here we introduce left eigenvectors.\n",
    "\n",
    "Left eigenvectors will play important roles in what follows, including that of stochastic steady states for dynamic models under a Markov assumption.\n",
    "\n",
    "We will talk more about this later, but for now, let’s define left eigenvectors.\n",
    "\n",
    "A vector $ w $ is called a left eigenvector of $ A $ if $ w $ is an eigenvector of $ A^\\top $.\n",
    "\n",
    "In other words, if $ w $ is a left eigenvector of matrix $ A $, then $ A^\\top w = \\lambda w $, where $ \\lambda $ is the eigenvalue associated with the left eigenvector $ v $.\n",
    "\n",
    "This hints at how to compute left eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e27d2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[3, 2],\n",
    "              [1, 4]])\n",
    "\n",
    "# Compute right eigenvectors and eigenvalues\n",
    "λ_r, v = eig(A)\n",
    "\n",
    "# Compute left eigenvectors and eigenvalues\n",
    "λ_l, w = eig(A.T)\n",
    "\n",
    "print(\"Right Eigenvalues:\")\n",
    "print(λ_r)\n",
    "print(\"\\nRight Eigenvectors:\")\n",
    "print(v)\n",
    "print(\"\\nLeft Eigenvalues:\")\n",
    "print(λ_l)\n",
    "print(\"\\nLeft Eigenvectors:\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9b1d7",
   "metadata": {},
   "source": [
    "We can use `scipy.linalg.eig` with argument `left=True` to find left eigenvectors directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e6d85",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "eigenvals, ε, e = sp.linalg.eig(A, left=True)\n",
    "\n",
    "print(\"Right Eigenvalues:\")\n",
    "print(λ_r)\n",
    "print(\"\\nRight Eigenvectors:\")\n",
    "print(v)\n",
    "print(\"\\nLeft Eigenvalues:\")\n",
    "print(λ_l)\n",
    "print(\"\\nLeft Eigenvectors:\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48862688",
   "metadata": {},
   "source": [
    "Note that the eigenvalues for both left and right eigenvectors are the same, but the eigenvectors themselves are different.\n",
    "\n",
    "We can then take transpose to obtain $ A^\\top w = \\lambda w $ and obtain $ w^\\top A= \\lambda w^\\top $.\n",
    "\n",
    "This is a more common expression and where the name left eigenvectors originates.\n",
    "\n",
    "\n",
    "<a id='perron-frobe'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534b8da",
   "metadata": {},
   "source": [
    "### The Perron-Frobenius theorem\n",
    "\n",
    "For a square nonnegative matrix $ A $, the behavior of $ A^k $ as $ k \\to \\infty $ is controlled by the eigenvalue with the largest\n",
    "absolute value, often called the **dominant eigenvalue**.\n",
    "\n",
    "For any such matrix $ A $, the Perron-Frobenius Theorem characterizes certain\n",
    "properties of the dominant eigenvalue and its corresponding eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e1a8e",
   "metadata": {},
   "source": [
    "###  (Perron-Frobenius Theorem)\n",
    "\n",
    "If a matrix $ A \\geq 0 $ then,\n",
    "\n",
    "1. the dominant eigenvalue of $ A $, $ r(A) $, is real-valued and nonnegative.  \n",
    "1. for any other eigenvalue (possibly complex) $ \\lambda $ of $ A $, $ |\\lambda| \\leq r(A) $.  \n",
    "1. we can find a nonnegative and nonzero eigenvector $ v $ such that $ Av = r(A)v $.  \n",
    "\n",
    "\n",
    "Moreover if $ A $ is also irreducible then,\n",
    "\n",
    "1. the eigenvector $ v $ associated with the eigenvalue $ r(A) $ is strictly positive.  \n",
    "1. there exists no other positive eigenvector $ v $ (except scalar multiples of $ v $) associated with $ r(A) $.  \n",
    "\n",
    "\n",
    "If $ A $ is primitive then,\n",
    "\n",
    "1. the inequality $ |\\lambda| \\leq r(A) $ is **strict** for all eigenvalues $ \\lambda $ of $ A $ distinct from $ r(A) $, and  \n",
    "1. with $ v $ and $ w $ normalized so that the inner product of $ w $ and  $ v = 1 $, we have\n",
    "  $ r(A)^{-m} A^m $ converges to $ v w^{\\top} $ when $ m \\rightarrow \\infty $. The matrix $ v w^{\\top} $ is called the **Perron projection** of $ A $  \n",
    "\n",
    "\n",
    "(This is a relatively simple version of the theorem — for more details see\n",
    "[here](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem)).\n",
    "\n",
    "We will see applications of the theorem below.\n",
    "\n",
    "Let’s build our intuition for the theorem using a simple example we have seen [before](https://intro.quantecon.org/markov_chains_I.html#mc-eg1).\n",
    "\n",
    "Now let’s consider examples for each case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3535bf2",
   "metadata": {},
   "source": [
    "#### Example 1: irreducible matrix\n",
    "\n",
    "Consider the following irreducible matrix $ A $:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a79703",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[0, 1, 0],\n",
    "              [.5, 0, .5],\n",
    "              [0, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed97f4a",
   "metadata": {},
   "source": [
    "We can compute the dominant eigenvalue and the corresponding eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe290794",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "eig(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b237e",
   "metadata": {},
   "source": [
    "Now we can go through our checklist to verify the claims of the Perron-Frobenius Theorem for the irreducible matrix $ A $:\n",
    "\n",
    "1. The dominant eigenvalue is real-valued and non-negative.  \n",
    "1. All other eigenvalues have absolute values less than or equal to the dominant eigenvalue.  \n",
    "1. A non-negative and nonzero eigenvector is associated with the dominant eigenvalue.  \n",
    "1. As the matrix is irreducible, the eigenvector associated with the dominant eigenvalue is strictly positive.  \n",
    "1. There exists no other positive eigenvector associated with the dominant eigenvalue.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a39278",
   "metadata": {},
   "source": [
    "#### Example 2: primitive matrix\n",
    "\n",
    "Consider the following primitive matrix $ B $:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b2663",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "B = np.array([[0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 0]])\n",
    "\n",
    "np.linalg.matrix_power(B, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5edd5e",
   "metadata": {},
   "source": [
    "We compute the dominant eigenvalue and the corresponding eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef00b32",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "eig(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e77bca",
   "metadata": {},
   "source": [
    "Now let’s verify the claims of the Perron-Frobenius Theorem for the primitive matrix $ B $:\n",
    "\n",
    "1. The dominant eigenvalue is real-valued and non-negative.  \n",
    "1. All other eigenvalues have absolute values strictly less than the dominant eigenvalue.  \n",
    "1. A non-negative and nonzero eigenvector is associated with the dominant eigenvalue.  \n",
    "1. The eigenvector associated with the dominant eigenvalue is strictly positive.  \n",
    "1. There exists no other positive eigenvector associated with the dominant eigenvalue.  \n",
    "1. The inequality $ |\\lambda| < r(B) $ holds for all eigenvalues $ \\lambda $ of $ B $ distinct from the dominant eigenvalue.  \n",
    "\n",
    "\n",
    "Furthermore, we can verify the convergence property (7) of the theorem on the following examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb6202",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def compute_perron_projection(M):\n",
    "\n",
    "    eigval, v = eig(M)\n",
    "    eigval, w = eig(M.T)\n",
    "\n",
    "    r = np.max(eigval)\n",
    "\n",
    "    # Find the index of the dominant (Perron) eigenvalue\n",
    "    i = np.argmax(eigval)\n",
    "\n",
    "    # Get the Perron eigenvectors\n",
    "    v_P = v[:, i].reshape(-1, 1)\n",
    "    w_P = w[:, i].reshape(-1, 1)\n",
    "\n",
    "    # Normalize the left and right eigenvectors\n",
    "    norm_factor = w_P.T @ v_P\n",
    "    v_norm = v_P / norm_factor\n",
    "\n",
    "    # Compute the Perron projection matrix\n",
    "    P = v_norm @ w_P.T\n",
    "    return P, r\n",
    "\n",
    "def check_convergence(M):\n",
    "    P, r = compute_perron_projection(M)\n",
    "    print(\"Perron projection:\")\n",
    "    print(P)\n",
    "\n",
    "    # Define a list of values for n\n",
    "    n_list = [1, 10, 100, 1000, 10000]\n",
    "\n",
    "    for n in n_list:\n",
    "\n",
    "        # Compute (A/r)^n\n",
    "        M_n = np.linalg.matrix_power(M/r, n)\n",
    "\n",
    "        # Compute the difference between A^n / r^n and the Perron projection\n",
    "        diff = np.abs(M_n - P)\n",
    "\n",
    "        # Calculate the norm of the difference matrix\n",
    "        diff_norm = np.linalg.norm(diff, 'fro')\n",
    "        print(f\"n = {n}, error = {diff_norm:.10f}\")\n",
    "\n",
    "\n",
    "A1 = np.array([[1, 2],\n",
    "               [1, 4]])\n",
    "\n",
    "A2 = np.array([[0, 1, 1],\n",
    "               [1, 0, 1],\n",
    "               [1, 1, 0]])\n",
    "\n",
    "A3 = np.array([[0.971, 0.029, 0.1, 1],\n",
    "               [0.145, 0.778, 0.077, 0.59],\n",
    "               [0.1, 0.508, 0.492, 1.12],\n",
    "               [0.2, 0.8, 0.71, 0.95]])\n",
    "\n",
    "for M in A1, A2, A3:\n",
    "    print(\"Matrix:\")\n",
    "    print(M)\n",
    "    check_convergence(M)\n",
    "    print()\n",
    "    print(\"-\"*36)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9f682",
   "metadata": {},
   "source": [
    "The convergence is not observed in cases of non-primitive matrices.\n",
    "\n",
    "Let’s go through an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba23455",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "B = np.array([[0, 1, 1],\n",
    "              [1, 0, 0],\n",
    "              [1, 0, 0]])\n",
    "\n",
    "# This shows that the matrix is not primitive\n",
    "print(\"Matrix:\")\n",
    "print(B)\n",
    "print(\"100th power of matrix B:\")\n",
    "print(np.linalg.matrix_power(B, 100))\n",
    "\n",
    "check_convergence(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4461843",
   "metadata": {},
   "source": [
    "The result shows that the matrix is not primitive as it is not everywhere positive.\n",
    "\n",
    "These examples show how the Perron-Frobenius Theorem relates to the eigenvalues and eigenvectors of positive matrices and the convergence of the power of matrices.\n",
    "\n",
    "In fact we have already seen the theorem in action before in [the markov chain lecture](https://intro.quantecon.org/markov_chains_I.html#mc1_ex_1).\n",
    "\n",
    "\n",
    "<a id='spec-markov'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7babbb36",
   "metadata": {},
   "source": [
    "#### Example 3: Connection to Markov chains\n",
    "\n",
    "We are now prepared to bridge the languages spoken in the two lectures.\n",
    "\n",
    "A primitive matrix is both irreducible (or strongly connected in the language of [graph theory](https://intro.quantecon.org/networks.html#strongly-connected) and aperiodic.\n",
    "\n",
    "So Perron-Frobenius Theorem explains why both Imam and Temple matrix and Hamilton matrix converge to a stationary distribution, which is the Perron projection of the two matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca10cb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "P = np.array([[0.68, 0.12, 0.20],\n",
    "              [0.50, 0.24, 0.26],\n",
    "              [0.36, 0.18, 0.46]])\n",
    "\n",
    "print(compute_perron_projection(P)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6784ee6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "mc = qe.MarkovChain(P)\n",
    "ψ_star = mc.stationary_distributions[0]\n",
    "ψ_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e691d8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "P_hamilton = np.array([[0.971, 0.029, 0.000],\n",
    "                       [0.145, 0.778, 0.077],\n",
    "                       [0.000, 0.508, 0.492]])\n",
    "\n",
    "print(compute_perron_projection(P_hamilton)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9031e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "mc = qe.MarkovChain(P_hamilton)\n",
    "ψ_star = mc.stationary_distributions[0]\n",
    "ψ_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00443064",
   "metadata": {},
   "source": [
    "We can also verify other properties hinted by Perron-Frobenius in these stochastic matrices.\n",
    "\n",
    "Another example is the relationship between convergence gap and convergence rate.\n",
    "\n",
    "In the [exercise](https://intro.quantecon.org/markov_chains_I.html#mc1_ex_1), we stated that the convergence rate is determined by the spectral gap, the difference between the largest and the second largest eigenvalue.\n",
    "\n",
    "This can be proven using what we have learned here.\n",
    "\n",
    "Please note that we use $ \\mathbb{1} $ for a vector of ones in this lecture.\n",
    "\n",
    "With Markov model $ M $ with state space $ S $ and transition matrix $ P $, we can write $ P^t $ as\n",
    "\n",
    "$$\n",
    "P^t=\\sum_{i=1}^{n-1} \\lambda_i^t v_i w_i^{\\top}+\\mathbb{1} \\psi^*,\n",
    "$$\n",
    "\n",
    "This is proven in [[SS23](https://intro.quantecon.org/zreferences.html#id16)] and a nice discussion can be found [here](https://math.stackexchange.com/questions/2433997/can-all-matrices-be-decomposed-as-product-of-right-and-left-eigenvector).\n",
    "\n",
    "In this formula $ \\lambda_i $ is an eigenvalue of $ P $ with corresponding right and left eigenvectors $ v_i $ and $ w_i $ .\n",
    "\n",
    "Premultiplying $ P^t $ by arbitrary $ \\psi \\in \\mathscr{D}(S) $ and rearranging now gives\n",
    "\n",
    "$$\n",
    "\\psi P^t-\\psi^*=\\sum_{i=1}^{n-1} \\lambda_i^t \\psi v_i w_i^{\\top}\n",
    "$$\n",
    "\n",
    "Recall that eigenvalues are ordered from smallest to largest from $ i = 1 ... n $.\n",
    "\n",
    "As we have seen, the largest eigenvalue for a primitive stochastic matrix is one.\n",
    "\n",
    "This can be proven using [Gershgorin Circle Theorem](https://en.wikipedia.org/wiki/Gershgorin_circle_theorem),\n",
    "but it is out of the scope of this lecture.\n",
    "\n",
    "So by the statement (6) of Perron-Frobenius Theorem, $ \\lambda_i<1 $ for all $ i<n $, and $ \\lambda_n=1 $ when $ P $ is primitive (strongly connected and aperiodic).\n",
    "\n",
    "Hence, after taking the Euclidean norm deviation, we obtain\n",
    "\n",
    "$$\n",
    "\\left\\|\\psi P^t-\\psi^*\\right\\|=O\\left(\\eta^t\\right) \\quad \\text { where } \\quad \\eta:=\\left|\\lambda_{n-1}\\right|<1\n",
    "$$\n",
    "\n",
    "Thus, the rate of convergence is governed by the modulus of the second largest eigenvalue.\n",
    "\n",
    "\n",
    "<a id='la-neumann'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83b7f4",
   "metadata": {},
   "source": [
    "## The Neumann Series Lemma\n",
    "\n",
    "\n",
    "<a id='index-1'></a>\n",
    "In this section we present a famous result about series of matrices that has\n",
    "many applications in economics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46792c9",
   "metadata": {},
   "source": [
    "### Scalar series\n",
    "\n",
    "Here’s a fundamental result about series that you surely know:\n",
    "\n",
    "If $ a $ is a number and $ |a| < 1 $, then\n",
    "\n",
    "\n",
    "<a id='equation-gp-sum'></a>\n",
    "$$\n",
    "\\sum_{k=0}^{\\infty} a^k =\\frac{1}{1-a} = (1 - a)^{-1} \\tag{30.1}\n",
    "$$\n",
    "\n",
    "For a one-dimensional linear equation $ x = ax + b $ where x is unknown we can thus conclude that the solution $ x^{*} $ is given by:\n",
    "\n",
    "$$\n",
    "x^{*} = \\frac{b}{1-a} = \\sum_{k=0}^{\\infty} a^k b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15336931",
   "metadata": {},
   "source": [
    "### Matrix series\n",
    "\n",
    "A generalization of this idea exists in the matrix setting.\n",
    "\n",
    "Consider the system of equations $ x = Ax + b $ where $ A $ is an $ n \\times n $\n",
    "square matrix and $ x $ and $ b $ are both column vectors in $ \\mathbb{R}^n $.\n",
    "\n",
    "Using matrix algebra we can conclude that the solution to this system of equations will be given by:\n",
    "\n",
    "\n",
    "<a id='equation-neumann-eqn'></a>\n",
    "$$\n",
    "x^{*} = (I-A)^{-1}b \\tag{30.2}\n",
    "$$\n",
    "\n",
    "What guarantees the existence of a unique vector $ x^{*} $ that satisfies\n",
    "[(30.2)](#equation-neumann-eqn)?\n",
    "\n",
    "The following is a fundamental result in functional analysis that generalizes\n",
    "[(30.1)](#equation-gp-sum) to a multivariate case.\n",
    "\n",
    "\n",
    "<a id='neumann-series-lemma'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e28d7b",
   "metadata": {},
   "source": [
    "###  (Neumann Series Lemma)\n",
    "\n",
    "Let $ A $ be a square matrix and let $ A^k $ be the $ k $-th power of $ A $.\n",
    "\n",
    "Let $ r(A) $ be the **spectral radius** of $ A $, defined as $ \\max_i |\\lambda_i| $, where\n",
    "\n",
    "- $ \\{\\lambda_i\\}_i $ is the set of eigenvalues of $ A $ and  \n",
    "- $ |\\lambda_i| $ is the modulus of the complex number $ \\lambda_i $  \n",
    "\n",
    "\n",
    "Neumann’s Theorem states the following: If $ r(A) < 1 $, then $ I - A $ is invertible, and\n",
    "\n",
    "$$\n",
    "(I - A)^{-1} = \\sum_{k=0}^{\\infty} A^k\n",
    "$$\n",
    "\n",
    "We can see the Neumann Series Lemma in action in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1db43",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[0.4, 0.1],\n",
    "              [0.7, 0.2]])\n",
    "\n",
    "evals, evecs = eig(A)   # finding eigenvalues and eigenvectors\n",
    "\n",
    "r = max(abs(λ) for λ in evals)    # compute spectral radius\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f58f7",
   "metadata": {},
   "source": [
    "The spectral radius $ r(A) $ obtained is less than 1.\n",
    "\n",
    "Thus, we can apply the Neumann Series Lemma to find $ (I-A)^{-1} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bb5d8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "I = np.identity(2)      #2 x 2 identity matrix\n",
    "B = I - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b132f146",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "B_inverse = np.linalg.inv(B)     #direct inverse method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d52191",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A_sum = np.zeros((2,2))        #power series sum of A\n",
    "A_power = I\n",
    "for i in range(50):\n",
    "    A_sum += A_power\n",
    "    A_power = A_power @ A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d8053",
   "metadata": {},
   "source": [
    "Let’s check equality between the sum and the inverse methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c5111",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "np.allclose(A_sum, B_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c483ad",
   "metadata": {},
   "source": [
    "Although we truncate the infinite sum at $ k = 50 $, both methods give us the same\n",
    "result which illustrates the result of the Neumann Series Lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd95918",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132983ee",
   "metadata": {},
   "source": [
    "##  (Leontief’s Input-Output Model)Exercise 30.1\n",
    "\n",
    "[Wassily Leontief](https://en.wikipedia.org/wiki/Wassily_Leontief) developed a model of an economy with $ n $ sectors producing $ n $ different commodities representing the interdependencies of different sectors of an economy.\n",
    "\n",
    "Under this model some of the output is consumed internally by the industries and the rest is consumed by external consumers.\n",
    "\n",
    "We define a simple model with 3 sectors - agriculture, industry, and service.\n",
    "\n",
    "The following table describes how output is distributed within the economy:\n",
    "\n",
    "||Total output|Agriculture|Industry|Service|Consumer|\n",
    "|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|\n",
    "|Agriculture|$ x_1 $|0.3$ x_1 $|0.2$ x_2 $|0.3$ x_3 $|4|\n",
    "|Industry|$ x_2 $|0.2$ x_1 $|0.4$ x_2 $|0.3$ x_3 $|5|\n",
    "|Service|$ x_3 $|0.2$ x_1 $|0.5$ x_2 $|0.1$ x_3 $|12|\n",
    "The first row depicts how agriculture’s total output $ x_1 $ is distributed\n",
    "\n",
    "- $ 0.3x_1 $ is used as inputs within agriculture itself,  \n",
    "- $ 0.2x_2 $ is used as inputs by the industry sector to produce $ x_2 $ units,  \n",
    "- $ 0.3x_3 $ is used as inputs by the service sector to produce $ x_3 $ units and  \n",
    "- 4 units is the external demand by consumers.  \n",
    "\n",
    "\n",
    "We can transform this into a system of linear equations for the 3 sectors as\n",
    "given below:\n",
    "\n",
    "$$\n",
    "x_1 = 0.3x_1 + 0.2x_2 + 0.3x_3 + 4 \\\\\n",
    "    x_2 = 0.2x_1 + 0.4x_2 + 0.3x_3 + 5 \\\\\n",
    "    x_3 = 0.2x_1 + 0.5x_2 + 0.1x_3 + 12\n",
    "$$\n",
    "\n",
    "This can be transformed into the matrix equation $ x = Ax + d $ where\n",
    "\n",
    "$$\n",
    "x =\n",
    "\\begin{bmatrix}\n",
    "    x_1 \\\\\n",
    "    x_2 \\\\\n",
    "    x_3\n",
    "\\end{bmatrix}\n",
    ", \\; A =\n",
    "\\begin{bmatrix}\n",
    "    0.3 & 0.2 & 0.3 \\\\\n",
    "    0.2 & 0.4 & 0.3 \\\\\n",
    "    0.2 & 0.5 & 0.1\n",
    "\\end{bmatrix}\n",
    "\\; \\text{and} \\;\n",
    "d =\n",
    "\\begin{bmatrix}\n",
    "    4 \\\\\n",
    "    5 \\\\\n",
    "    12\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The solution $ x^{*} $ is given by the equation $ x^{*} = (I-A)^{-1} d $\n",
    "\n",
    "1. Since $ A $ is a nonnegative irreducible matrix, find the Perron-Frobenius eigenvalue of $ A $.  \n",
    "1. Use the Neumann Series Lemma to find the solution $ x^{*} $ if it exists.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc708a61",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 30.1 (Leontief’s Input-Output Model)](https://intro.quantecon.org/#eig_ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b37a2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[0.3, 0.2, 0.3],\n",
    "              [0.2, 0.4, 0.3],\n",
    "              [0.2, 0.5, 0.1]])\n",
    "\n",
    "evals, evecs = eig(A)\n",
    "\n",
    "r = max(abs(λ) for λ in evals)   #dominant eigenvalue/spectral radius\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a5169",
   "metadata": {},
   "source": [
    "Since we have $ r(A) < 1 $ we can thus find the solution using the Neumann Series Lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24af510",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "I = np.identity(3)\n",
    "B = I - A\n",
    "\n",
    "d = np.array([4, 5, 12])\n",
    "d.shape = (3,1)\n",
    "\n",
    "B_inv = np.linalg.inv(B)\n",
    "x_star = B_inv @ d\n",
    "print(x_star)"
   ]
  }
 ],
 "metadata": {
  "date": 1687926031.0352223,
  "filename": "eigen_II.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Spectral Theory"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}